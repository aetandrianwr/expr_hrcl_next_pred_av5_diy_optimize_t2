# Architectural Justification: Ablation Study Notebook

## ğŸ““ File
`architecture_justification_ablation_study.ipynb`

## ğŸ¯ Purpose
This notebook provides **rigorous, empirical justification** for the History-Centric Model architecture through comprehensive ablation studies and comparative experiments.

## ğŸ”¬ Research Questions Answered

1. **Why do we need the History Scoring Module?**
   - Evidence: ~84% of next locations appear in visit history
   - Analysis: History coverage study + baseline performance

2. **Why do we need the Transformer branch?**
   - Evidence: Learns complex temporal patterns beyond simple recency/frequency
   - Analysis: Transformer-Only vs. History-Only comparison

3. **Why do we need BOTH components together?**
   - Evidence: Hybrid achieves superior performance
   - Analysis: Ablation studies showing complementary strengths

## ğŸ“Š Models Evaluated

| Model | Description | Purpose |
|-------|-------------|---------|
| **History-Only** | Pure recency + frequency scoring | Upper bound of non-learned approach |
| **Transformer-Only** | Deep learning without history bias | Can DL alone match history-centric? |
| **History-Centric** | Full hybrid architecture | Our proposed solution |

## ğŸ“ Key Features

- âœ… **Self-Contained**: No external project dependencies
- âœ… **Reproducible**: Fixed seed (42), same data splits
- âœ… **Comprehensive**: 25 cells with detailed explanations
- âœ… **Executable**: Run top-to-bottom without errors
- âœ… **Educational**: Clear explanations at every step
- âœ… **Rigorous**: Evidence-based conclusions

## ğŸš€ How to Run

```bash
cd notebooks/
jupyter notebook architecture_justification_ablation_study.ipynb
```

Then:
1. Run all cells (Cell â†’ Run All)
2. Review results and visualizations
3. Read conclusions

**Note:** Training takes ~10-20 minutes (20 epochs). For full results, increase to 120 epochs.

## ğŸ“ˆ Expected Results

| Metric | History-Only | Transformer-Only | History-Centric |
|--------|--------------|------------------|-----------------|
| Acc@1  | ~35-40%      | ~42-47%          | ~47-52% |
| Acc@5  | ~60-65%      | ~68-73%          | ~72-77% |
| MRR    | ~45-50%      | ~55-60%          | ~60-65% |

The History-Centric model outperforms both baselines, demonstrating the value of combining history scoring with transformer learning.

## ğŸ“š Notebook Structure

1. **Executive Summary**: Research questions and design
2. **Setup**: Imports and environment
3. **Data Loading**: GeoLife dataset
4. **History Coverage Analysis**: ~84% coverage finding
5. **PyTorch Dataset**: Data preparation
6. **Model Implementations**: 3 model variants
7. **Evaluation Metrics**: Acc@K, MRR, F1
8. **Training Function**: Training loop
9. **Experiments**: Train and evaluate all models
10. **Results Comparison**: Tables and visualizations
11. **Conclusions**: Architectural justification

## âœ… Reproducibility

- Random seed: 42
- PyTorch version: â‰¥1.12
- Data: GeoLife preprocessed splits
- Hyperparameters: Documented in code

## ğŸ“ Citation

If you use this analysis in your research, please cite the project and mention the ablation study notebook.

## ğŸ¤ Contributing

This notebook is part of the History-Centric Next-Location Prediction project. For questions or improvements, please open an issue in the repository.

---

**Last Updated:** November 30, 2024
**Status:** âœ… Complete and Tested
**Location:** `/notebooks/architecture_justification_ablation_study.ipynb`
